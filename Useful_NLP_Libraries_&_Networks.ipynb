{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Useful NLP Libraries & Networks | Vikash Kumar | wiryvikash15@gmail.com**\n"
      ],
      "metadata": {
        "id": "aVEi7zNYJ6Rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**1. Compare and contrast NLTK and spaCy in terms of features, ease of use, and performance.**"
      ],
      "metadata": {
        "id": "FzDZdwaHqlwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- **Features**: NLTK is a large teaching-oriented toolkit with many algorithms (tokenization, stemming, parsing, classic ML classifiers, etc.), while spaCy focuses on a smaller, production-ready set of core NLP tasks (tokenization, POS tagging, dependency parsing, NER, vectors).\n",
        "\n",
        "- **Ease of use**: NLTK exposes low-level components, which is flexible but requires more code; spaCy provides a streamlined pipeline API that is easier for end-to-end processing once you understand its objects.\n",
        "\n",
        "- **Performance**: NLTK is pure Python and usually slower for large-scale workloads, whereas spaCy is optimized in Cython and significantly faster and more memory-efficient for large text corpora.\n",
        "\n",
        "- **Typical use**: NLTK is often preferred for learning, experimentation, and custom rule-based workflows; spaCy is commonly used in production systems where speed, robustness, and pretrained models are important."
      ],
      "metadata": {
        "id": "Ut5Itq_PqoYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**2. What is TextBlob and how does it simplify common NLP tasks like sentiment analysis and translation?**"
      ],
      "metadata": {
        "id": "Xhva72PXqw23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- TextBlob is a Python library that wraps NLTK and pattern to provide a simple, high-level API for common NLP tasks such as tokenization, POS tagging, noun phrase extraction, sentiment analysis, and translation.\n",
        "\n",
        "- It simplifies sentiment analysis by exposing a single `sentiment` property that returns polarity and subjectivity scores, instead of requiring manual model training or low-level feature engineering.\n",
        "\n",
        "- For translation and language processing, TextBlob uses underlying services or models and exposes them via simple methods like `.translate()` and `.detect_language()`, making prototyping very fast."
      ],
      "metadata": {
        "id": "UFCD-RIpq0e2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**3. Explain the role of Stanford NLP in academic and industry NLP projects.**"
      ],
      "metadata": {
        "id": "jOwOWvbWq6jE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- Stanford NLP (including the CoreNLP suite) provides a collection of high-quality, linguistically informed tools such as tokenization, POS tagging, parsing, coreference resolution, and sentiment analysis that are widely used in academic research.\n",
        "\n",
        "- Its models are trained on well-curated corpora and are often considered strong baselines in papers, which is why many research projects use Stanford NLP components for reproducible experiments.\n",
        "\n",
        "- In industry, Stanford NLP (often via CoreNLP servers or wrappers) is used when robust, well-tested classical NLP pipelines are sufficient and when Java-based, language-rich tools integrate well with existing enterprise stacks."
      ],
      "metadata": {
        "id": "q3mRprVoq-SX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**4. Describe the architecture and functioning of a Recurrent Neural Network (RNN).**"
      ],
      "metadata": {
        "id": "006BLPhsrEgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- An RNN processes sequences by maintaining a **hidden state** that is updated at each time step using the current input and the previous hidden state, allowing information to flow across time.\n",
        "\n",
        "- At time step t, a basic RNN computes h_t = tanh(W_x * x_t + W_h * h_(t-1) + b) and then produces an output y_t, so the network can, in principle, capture temporal dependencies in text or time series.\n",
        "\n",
        "- During training, backpropagation through time (BPTT) unfolds the network across time steps and computes gradients, but standard RNNs can suffer from vanishing and exploding gradients for long sequences."
      ],
      "metadata": {
        "id": "K5VbxeGdrINl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**5. What is the key difference between LSTM and GRU networks in NLP applications?**"
      ],
      "metadata": {
        "id": "nIKq3X-RrOxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- LSTMs use three gates (input, forget, output) and maintain both a cell state and a hidden state, giving them fine-grained control over what information to keep, write, and expose.\n",
        "\n",
        "- GRUs use only two gates (reset and update) and maintain a single hidden state, resulting in fewer parameters and simpler computations.\n",
        "\n",
        "- In practice, LSTMs often perform slightly better on tasks requiring modeling very long-range dependencies, while GRUs tend to train faster and can match LSTM performance on many NLP tasks such as sentiment analysis or sequence labeling."
      ],
      "metadata": {
        "id": "6lGy7zAWrUIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**6. Write a Python program using TextBlob to perform sentiment analysis on the following paragraph of text:**\n",
        "\n",
        "**\"I had a great experience using the new mobile banking app. The interface is intuitive, and customer support was quick to resolve my issue. However, the app did crash once during a transaction, which was frustrating\"**\n",
        "\n",
        "**Your program should print out the polarity and subjectivity scores.**"
      ],
      "metadata": {
        "id": "oWfYYGA0rbdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import TextBlob\n",
        "!pip install -q textblob\n",
        "from textblob import TextBlob\n",
        "\n",
        "text = (\"I had a great experience using the new mobile banking app. \"\n",
        "        \"The interface is intuitive, and customer support was quick to resolve my issue. \"\n",
        "        \"However, the app did crash once during a transaction, which was frustrating\")\n",
        "\n",
        "blob = TextBlob(text)\n",
        "\n",
        "polarity = blob.sentiment.polarity   # in [-1, 1]\n",
        "subjectivity = blob.sentiment.subjectivity  # in [0, 1]\n",
        "\n",
        "print(\"Text:\", text)\n",
        "print(\"Polarity:\", polarity)\n",
        "print(\"Subjectivity:\", subjectivity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvwxJJzure_L",
        "outputId": "06f9dd33-f611-479b-993d-1144721fef84"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I had a great experience using the new mobile banking app. The interface is intuitive, and customer support was quick to resolve my issue. However, the app did crash once during a transaction, which was frustrating\n",
            "Polarity: 0.21742424242424244\n",
            "Subjectivity: 0.6511363636363636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**7. Given the sample paragraph below, perform string tokenization and frequency distribution using Python and NLTK:**\n",
        "\n",
        "**\"Natural Language Processing (NLP) is a fascinating field that combines linguistics, computer science, and artificial intelligence. It enables machines to understand, interpret, and generate human language. Applications of NLP include chatbots, sentiment analysis, and machine translation. As technology advances, the role of NLP in modern solutions is becoming increasingly critical.\"**"
      ],
      "metadata": {
        "id": "oTETcsQQrlN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q nltk"
      ],
      "metadata": {
        "id": "dAm1dUMP1SHU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Input text [cite: 32]\n",
        "text = \"\"\"Natural Language Processing (NLP) is a fascinating field that combines linguistics,\n",
        "computer science, and artificial intelligence. It enables machines to understand,\n",
        "interpret, and generate human language. Applications of NLP include chatbots,\n",
        "sentiment analysis, and machine translation. As technology advances, the role of NLP\n",
        "in modern solutions is becoming increasingly critical.\"\"\"\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text.lower()) # Lowercasing for better frequency count\n",
        "\n",
        "# Frequency Distribution\n",
        "fdist = FreqDist(tokens)\n",
        "\n",
        "# Output\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"\\nFrequency Distribution (Top 10):\")\n",
        "for word, frequency in fdist.most_common(10):\n",
        "    print(f\"{word}: {frequency}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxnPjXTjrpHk",
        "outputId": "50eb29ea-7225-4c5f-8f97-741e36ece71f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['natural', 'language', 'processing', '(', 'nlp', ')', 'is', 'a', 'fascinating', 'field', 'that', 'combines', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', '.', 'it', 'enables', 'machines', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.', 'applications', 'of', 'nlp', 'include', 'chatbots', ',', 'sentiment', 'analysis', ',', 'and', 'machine', 'translation', '.', 'as', 'technology', 'advances', ',', 'the', 'role', 'of', 'nlp', 'in', 'modern', 'solutions', 'is', 'becoming', 'increasingly', 'critical', '.']\n",
            "\n",
            "Frequency Distribution (Top 10):\n",
            ",: 7\n",
            ".: 4\n",
            "nlp: 3\n",
            "and: 3\n",
            "language: 2\n",
            "is: 2\n",
            "of: 2\n",
            "natural: 1\n",
            "processing: 1\n",
            "(: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**8. Implement a basic LSTM model in Keras for a text classification task using the following dummy dataset. Your model should classify sentences as either positive (1) or negative (0).**\n",
        "\n",
        "```python\n",
        "texts = [\n",
        "    \"I love this project\",          # Positive\n",
        "    \"This is an amazing experience\",# Positive\n",
        "    \"I hate waiting in line\",       # Negative\n",
        "    \"This is the worst service\",    # Negative\n",
        "    \"Absolutely fantastic!\"         # Positive\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 0, 1]\n",
        "```\n",
        "\n",
        "**Preprocess the text, tokenize it, pad sequences, and build an LSTM model to train on this data. You may use Keras with TensorFlow backend.**"
      ],
      "metadata": {
        "id": "WUE9DPLmrvz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Dataset\n",
        "texts = [\n",
        "    \"I love this project\",\n",
        "    \"This is an amazing experience\",\n",
        "    \"I hate waiting in line\",\n",
        "    \"This is the worst service\",\n",
        "    \"Absolutely fantastic!\"\n",
        "]\n",
        "labels = np.array([1, 1, 0, 0, 1])\n",
        "\n",
        "# Preprocessing\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "data = pad_sequences(sequences)\n",
        "\n",
        "# Build LSTM Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=100, output_dim=8, input_length=data.shape[1]),\n",
        "    LSTM(16),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train (Briefly for demonstration)\n",
        "model.fit(data, labels, epochs=10, verbose=0)\n",
        "\n",
        "print(\"Model built and trained successfully.\")\n",
        "print(\"Sample prediction for 'I love this project':\", model.predict(data[:1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38zc1Z7Gr0c2",
        "outputId": "27d12444-d6a3-4dbb-9822-b2d3fba1101c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model built and trained successfully.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "Sample prediction for 'I love this project': [[0.5117024]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**9. Using spaCy, build a simple NLP pipeline that includes tokenization, lemmatization, and entity recognition. Use the following paragraph as your dataset:**\n",
        "\n",
        "**\"Homi Jehangir Bhaba was an Indian nuclear physicist who played a key role in the development of India's atomic energy program. He was the founding director of the Tata Institute of Fundamental Research (TIFR) and was instrumental in establishing the Atomic Energy Commission of India.\"**\n",
        "\n",
        "**Write a Python program that processes this text using spaCy, then prints tokens, their lemmas, and any named entities found.**"
      ],
      "metadata": {
        "id": "y1GXUVtyr7dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Input text\n",
        "text = \"\"\"Homi Jehangir Bhaba was an Indian nuclear physicist who played a key role in the\n",
        "development of India's atomic energy program. He was the founding director of the Tata\n",
        "Institute of Fundamental Research (TIFR) and was instrumental in establishing the\n",
        "Atomic Energy Commission of India.\"\"\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Tokenization and Lemmatization\n",
        "print(f\"{'Token':<20} | {'Lemma':<20}\")\n",
        "print(\"-\" * 45)\n",
        "for token in list(doc)[:10]: # Showing first 10 for brevity\n",
        "    print(f\"{token.text:<20} | {token.lemma_:<20}\")\n",
        "\n",
        "# Named Entity Recognition\n",
        "print(\"\\nNamed Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text} ({ent.label_})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqCuZIKJr_4d",
        "outputId": "5b624829-f724-4eeb-e001-673aa552f38d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token                | Lemma               \n",
            "---------------------------------------------\n",
            "Homi                 | Homi                \n",
            "Jehangir             | Jehangir            \n",
            "Bhaba                | Bhaba               \n",
            "was                  | be                  \n",
            "an                   | an                  \n",
            "Indian               | indian              \n",
            "nuclear              | nuclear             \n",
            "physicist            | physicist           \n",
            "who                  | who                 \n",
            "played               | play                \n",
            "\n",
            "Named Entities:\n",
            "Homi Jehangir Bhaba (FAC)\n",
            "Indian (NORP)\n",
            "India (GPE)\n",
            "the Tata \n",
            "Institute of Fundamental Research (ORG)\n",
            "Atomic Energy Commission of India (ORG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**10. You are working on a chatbot for a mental health platform. Explain how you would leverage LSTM or GRU networks along with libraries like spaCy or Stanford NLP to understand and respond to user input effectively. Detail your architecture, data preprocessing pipeline, and any ethical considerations.**"
      ],
      "metadata": {
        "id": "WWEBFyvLsGmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Overall architecture:**\n",
        "\n",
        "- Use spaCy or Stanford NLP to preprocess user messages: tokenization, lemmatization, POS tagging, and entity recognition (e.g., people, dates, medical terms).\n",
        "\n",
        "- Feed the processed text into an LSTM or GRU-based sequence model that performs intent classification (e.g., \"anxiety\", \"crisis\", \"general support\") and maybe sequence labeling for important slots (e.g., duration, triggers).\n",
        "\n",
        "- Use a response generation layer: rule-based templates, retrieval from a curated response bank, or a separate neural decoder, constrained by safety rules.\n",
        "\n",
        "**Data preprocessing pipeline:**\n",
        "\n",
        "- Clean text (lowercasing where appropriate, removing obvious noise but preserving clinically relevant cues like negation: \"not okay\", \"no hope\").\n",
        "\n",
        "- Use spaCy to extract entities and syntactic information, and convert tokens to integer IDs via a tokenizer suitable for the LSTM/GRU model.\n",
        "\n",
        "- Handle long conversations with truncation or hierarchical RNNs: message-level encoder plus conversation-level encoder.\n",
        "\n",
        "**Ethical considerations:**\n",
        "\n",
        "- Ensure strict privacy: anonymize data, remove identifying entities where possible, and store logs securely.\n",
        "\n",
        "- Implement crisis-detection intents that trigger escalation: e.g., if the model detects self-harm risk, route to human professionals and show emergency resources rather than automated chit-chat.\n",
        "\n",
        "- Clearly communicate to users that the chatbot is not a licensed therapist and should not replace professional medical advice."
      ],
      "metadata": {
        "id": "jhNEMj5lsM9i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HE-jYgAz1E27"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}