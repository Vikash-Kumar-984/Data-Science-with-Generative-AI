{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble Learning | Vikash Kumar | wiryvikash15@gmail.com**"
      ],
      "metadata": {
        "id": "V0heaPUB9LbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is Ensemble Learning in machine learning? Explain the key idea behind it.**\n",
        "\n",
        "Ensemble Learning is a machine learning paradigm where multiple individual models, often called \"weak learners\" or \"base models,\" are strategically combined to solve the same problem. Instead of relying on a single model, an ensemble leverages the collective intelligence of several models to produce a final prediction that is more accurate, stable, and robust.\n",
        "\n",
        "The key idea behind ensemble learning is the \"wisdom of the crowd.\" The central principle is that a diverse group of models, when combined, can average out or vote on their individual errors, biases, and weaknesses. If one model makes an incorrect prediction, other models in the ensemble have a chance to correct it. This collaboration helps to:\n",
        "\n",
        "Reduce Variance: By averaging multiple models, the final prediction is less sensitive to the specific noise or quirks in the training data (e.g., Bagging).\n",
        "\n",
        "Reduce Bias: By sequentially training models to fix the errors of their predecessors, the ensemble can learn a more accurate underlying pattern (e.g., Boosting).\n",
        "\n",
        "Ultimately, this leads to a model with better generalization performance on new, unseen data compared to any of the individual models acting alone."
      ],
      "metadata": {
        "id": "1vnmkG0WVwa4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What is the difference between Bagging and Boosting?**\n",
        "\n",
        "Bagging and Boosting are two of the most popular ensemble techniques, but they differ fundamentally in their approach to combining models.\n",
        "\n",
        "**Bagging (Bootstrap Aggregating)**\n",
        "\n",
        "\n",
        "- Models are trained in parallel and independently of each other.\n",
        "\n",
        "- Each model is trained on a random subset of the original data, created using bootstrap sampling (sampling with replacement).\n",
        "\n",
        "- To reduce variance and prevent overfitting. It's most effective with low-bias, high-variance models (like deep decision trees).\n",
        "\n",
        "- All models have an equal say in the final prediction (e.g., through simple voting or averaging).\n",
        "\n",
        "- Example Algorithms: Random Forest, Bagging Classifiers/Regressors.\n",
        "\n",
        "**Boosting**\n",
        "\n",
        "- Models are trained sequentially, where each new model learns from the mistakes of the previous one.\n",
        "\n",
        "- All models are trained on the entire dataset. However, data points misclassified by previous models are given higher weights for the next model.\n",
        "\n",
        "- To reduce bias and build a single, highly accurate predictor. It turns a collection of weak learners into a single strong learner.\n",
        "\n",
        "- Models are weighted based on their performance. Better-performing models have a greater influence on the final prediction.\n",
        "\n",
        "- Example Algorithms: AdaBoost, Gradient Boosting (GBM), XGBoost, LightGBM.\n"
      ],
      "metadata": {
        "id": "2fVy_DTuZVxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What is bootstrap sampling and what role does it play in Bagging methods like Random Forest?**\n",
        "\n",
        "Bootstrap Sampling is a resampling method used to create data subsets from an original dataset. It works by sampling with replacement. This means that when a data point is selected from the original dataset to be in the subset, it is not removed from the pool of potential choices. As a result, a single data point can appear multiple times, once, or not at all in any given bootstrap sample. Each bootstrap sample is the same size as the original dataset.\n",
        "\n",
        "In Bagging methods like Random Forest, bootstrap sampling plays a crucial role:\n",
        "\n",
        "- Creates Data Diversity: It is the core mechanism that generates different training datasets for each of the base models (decision trees). Since each tree is trained on a slightly different subset of the data, the trees learn different patterns and features.\n",
        "\n",
        "- Reduces Model Correlation: This data diversity ensures that the individual trees in the forest are not highly correlated with one another. If the trees were all trained on the exact same data, they would be very similar, and the ensemble would offer little benefit. By decorrelating the trees, their combined prediction becomes much more robust.\n",
        "\n",
        "- Enables Out-of-Bag (OOB) Evaluation: As a natural byproduct, about one-third of the original data points are left out of any given bootstrap sample. These \"Out-of-Bag\" samples can be used as a built-in validation set to evaluate the model's performance without requiring a separate train-test split."
      ],
      "metadata": {
        "id": "O4wsV0eQaZ7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. What are Out-of-Bag (OOB) samples and how is OOB score used to evaluate ensemble models?**\n",
        "\n",
        "Out-of-Bag (OOB) samples are the data points from the original training set that are not included in a specific bootstrap sample used to train a base model (like a decision tree in a Random Forest). On average, for any given base model, approximately 36.8% of the original data points are OOB.\n",
        "\n",
        "The OOB score is a method for evaluating the performance of an ensemble model using these OOB samples, effectively serving as a built-in cross-validation mechanism. Here's how it's calculated:\n",
        "\n",
        "- For each data point (x_i) in the original dataset, identify all the trees in the forest that did not use x_i during their training.\n",
        "\n",
        "- Use this sub-ensemble of trees (where x_i was an OOB sample) to make a prediction for x_i.\n",
        "\n",
        "- Repeat this process for all data points in the dataset.\n",
        "\n",
        "- The OOB score is then calculated by comparing these OOB predictions against the actual target values. For classification, this is typically accuracy, and for regression, it is often the R-squared score.\n",
        "\n",
        "Because the predictions for each data point are made by trees that never saw that point during training, the OOB score provides an unbiased estimate of the model's performance on unseen data."
      ],
      "metadata": {
        "id": "H_NqOKjeam9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Compare feature importance analysis in a single Decision Tree vs. a Random Forest.**\n",
        "\n",
        "Both a single Decision Tree and a Random Forest can provide feature importance scores, but the quality and reliability of these scores differ significantly.\n",
        "\n",
        "**Single Decision Tree:**\n",
        "\n",
        "**Calculation:** Feature importance is calculated based on how much a feature decreases the impurity (e.g., Gini impurity) in the nodes where it is used for a split. Features used higher up in the tree that lead to large reductions in impurity are considered more important.\n",
        "\n",
        "**Limitation:** The results are often unstable and have high variance. A small change in the training data can lead to a completely different tree structure, drastically changing which features are deemed important. It can also be biased toward features with high cardinality (many unique values).\n",
        "\n",
        "**Random Forest:**\n",
        "\n",
        "**Calculation:** The feature importance for a Random Forest is calculated by averaging the impurity-based feature importance of that feature across all the trees in the forest.\n",
        "\n",
        "**Advantage:** This averaging process makes the feature importance scores much more robust, stable, and reliable. By aggregating the results from hundreds of different trees (each built on a different data sample), the variance associated with a single tree is reduced. This gives a more accurate and generalizable estimate of a feature's true predictive power.\n",
        "\n",
        "In short, a Random Forest provides a more trustworthy assessment of feature importance because it's based on the consensus of many diverse models rather than the perspective of just one."
      ],
      "metadata": {
        "id": "hM6IgsZGavy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Write a Python program to:**\n",
        "\n",
        "- **Load the Breast Cancer dataset using\n",
        "sklearn.datasets.load_breast_cancer()**\n",
        "\n",
        "- **Train a Random Forest Classifier**\n",
        "\n",
        "- **Print the top 5 most important features based on feature importance scores.**"
      ],
      "metadata": {
        "id": "RX-5Br4_a3Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "feature_names = cancer.feature_names\n",
        "\n",
        "# n_estimators=100 (the number of trees in the forest)\n",
        "# random_state=42 ensures reproducibility\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X, y)\n",
        "\n",
        "# feature importance scores\n",
        "importances = rf_classifier.feature_importances_\n",
        "\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': importances\n",
        "})\n",
        "\n",
        "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(\"Top 5 most important features:\")\n",
        "print(feature_importance_df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86vi_5k7aufG",
        "outputId": "b387e00a-9092-499a-8d19-b99ef734bdf4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most important features:\n",
            "                 feature  importance\n",
            "23            worst area    0.139357\n",
            "27  worst concave points    0.132225\n",
            "7    mean concave points    0.107046\n",
            "20          worst radius    0.082848\n",
            "22       worst perimeter    0.080850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Write a Python program to:**\n",
        "\n",
        "- **Train a Bagging Classifier using Decision Trees on the Iris dataset**\n",
        "\n",
        "- **Evaluate its accuracy and compare with a single Decision Tree**"
      ],
      "metadata": {
        "id": "cHF4o8AAa956"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Train and evaluate a single Decision Tree\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "# Train and evaluate a Bagging Classifier using Decision Trees\n",
        "bagging_classifier = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_classifier.predict(X_test)\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "\n",
        "print(\"--- Model Accuracy Comparison ---\")\n",
        "print(f\"Single Decision Tree Accuracy: {accuracy_dt:.4f}\")\n",
        "print(f\"Bagging Classifier Accuracy:   {accuracy_bagging:.4f}\")\n",
        "\n",
        "if accuracy_bagging > accuracy_dt:\n",
        "    print(\"\\nThe Bagging Classifier performed better than the single Decision Tree.\")\n",
        "else:\n",
        "    print(\"\\nThe single Decision Tree performed as well as or better than the Bagging Classifier.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAiuoBAua6Uh",
        "outputId": "53f3579b-070f-4c66-950a-bbf3019cbe52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model Accuracy Comparison ---\n",
            "Single Decision Tree Accuracy: 0.9333\n",
            "Bagging Classifier Accuracy:   0.9333\n",
            "\n",
            "The single Decision Tree performed as well as or better than the Bagging Classifier.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Write a Python program to:**\n",
        "\n",
        "**- Train a Random Forest Classifier**\n",
        "\n",
        "**- Tune hyperparameters max_depth and n_estimators using GridSearchCV**\n",
        "**- Print the best parameters and final accuracy**"
      ],
      "metadata": {
        "id": "LCEEFf4vbC1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# hyperparameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],  # The number of trees in the forest\n",
        "    'max_depth': [None, 5, 10, 20]      # The maximum depth of the tree\n",
        "}\n",
        "\n",
        "# cv=5 means 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "\n",
        "print(\"Running GridSearchCV...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "final_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nFinal accuracy of the tuned model: {final_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqIc8SASa_z3",
        "outputId": "41e99159-b007-4325-c8f9-cd9c094fb6a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running GridSearchCV...\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "\n",
            "Best parameters found:\n",
            "{'max_depth': None, 'n_estimators': 100}\n",
            "\n",
            "Final accuracy of the tuned model: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. **Write a Python program to:**\n",
        "\n",
        "**- Train a Bagging Regressor and a Random Forest Regressor on the California\n",
        "Housing dataset**\n",
        "\n",
        "**- Compare their Mean Squared Errors (MSE)**"
      ],
      "metadata": {
        "id": "8-8kESCDbHj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Training Bagging Regressor...\")\n",
        "bagging_reg = BaggingRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "bagging_reg.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_reg.predict(X_test)\n",
        "mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
        "\n",
        "print(\"Training Random Forest Regressor...\")\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "y_pred_rf = rf_reg.predict(X_test)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\n--- Model MSE Comparison ---\")\n",
        "print(f\"Bagging Regressor MSE:      {mse_bagging:.4f}\")\n",
        "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")\n",
        "\n",
        "if mse_rf < mse_bagging:\n",
        "    print(\"\\nRandom Forest Regressor has a lower MSE, indicating better performance.\")\n",
        "else:\n",
        "    print(\"\\nBagging Regressor has a lower or equal MSE.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqGDrfwzbEky",
        "outputId": "b40b534d-11d0-44b6-9f91-869ea24f9d84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bagging Regressor...\n",
            "Training Random Forest Regressor...\n",
            "\n",
            "--- Model MSE Comparison ---\n",
            "Bagging Regressor MSE:      0.2568\n",
            "Random Forest Regressor MSE: 0.2565\n",
            "\n",
            "Random Forest Regressor has a lower MSE, indicating better performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. You are working as a data scientist at a financial institution to predict loan\n",
        "default. You have access to customer demographic and transaction history data.**\n",
        "\n",
        "**You decide to use ensemble techniques to increase model performance.**\n",
        "\n",
        "**Explain your step-by-step approach to:**\n",
        "\n",
        "**- Choose between Bagging or Boosting**\n",
        "\n",
        "**-Handle overfitting**\n",
        "\n",
        "**- Select base models**\n",
        "\n",
        "**- Evaluate performance using cross-validation**\n",
        "\n",
        "**- Justify how ensemble learning improves decision-making in this real-world\n",
        "context.**"
      ],
      "metadata": {
        "id": "poepwsB68Pfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The step-by-step approach to building a robust loan default prediction model using ensemble techniques for a financial institution.\n",
        "\n",
        "**1. Choose between Bagging or Boosting**\n",
        "\n",
        "My initial choice would be a Boosting algorithm, such as XGBoost or LightGBM.\n",
        "\n",
        "**Justification:** Loan default prediction is a problem where accuracy and minimizing false negatives (failing to predict a default) are critical. Boosting algorithms excel at reducing bias and creating highly predictive models by sequentially focusing on difficult-to-classify cases. This is ideal for capturing the complex, subtle patterns in financial data that separate defaulters from non-defaulters. While Bagging (like Random Forest) is great for stability, Boosting often provides a superior predictive edge in classification tasks like this.\n",
        "\n",
        "**2. Select Base Models**\n",
        "\n",
        "The base models for either Bagging or Boosting would be Decision Trees.\n",
        "\n",
        "**Justification:** Decision trees are excellent base learners for ensembles because they are capable of capturing complex, non-linear interactions between features (e.g., how income interacts with loan amount and credit score). They are \"low-bias, high-variance\" models (when grown deep), which is the perfect characteristic for methods like Bagging and Boosting to exploit to create a strong, generalized final model.\n",
        "\n",
        "**3. Handle Overfitting**\n",
        "\n",
        "Overfitting is a major risk, so I would implement a multi-pronged strategy:\n",
        "\n",
        "**Hyperparameter Tuning:** I would use GridSearchCV or RandomizedSearchCV to systematically tune key regularization parameters. For XGBoost, this would include max_depth (tree depth), learning_rate (eta), subsample (fraction of data used per tree), and gamma (minimum loss reduction to split). For Random Forest, it would be n_estimators, max_depth, and min_samples_leaf.\n",
        "\n",
        "**Early Stopping:** Specifically for Boosting, I would use an early stopping mechanism. This involves monitoring the model's performance on a separate validation set during training and stopping the process once the performance stops improving for a certain number of iterations, preventing the model from becoming overly complex.\n",
        "\n",
        "**Cross-Validation:** This is key and is detailed in the next step.\n",
        "\n",
        "**4. Evaluate Performance using Cross-Validation**\n",
        "\n",
        "To get a reliable estimate of the model's performance and ensure it generalizes well to new customers, I would use Stratified k-Fold Cross-Validation (e.g., with k=5 or k=10).\n",
        "\n",
        "**Justification:** Loan default is an imbalanced classification problem (many more non-defaulters than defaulters). Stratified sampling ensures that each fold of the cross-validation has the same percentage of defaulters as the original dataset, leading to a more reliable evaluation.\n",
        "\n",
        "**Evaluation Metrics:** Accuracy is a misleading metric here. I would focus on:\n",
        "\n",
        "**AUC-ROC Score:** To measure the model's ability to distinguish between the two classes.\n",
        "\n",
        "**Precision-Recall Curve (AUC-PR):** More informative than ROC for imbalanced data, as it focuses on the performance of the positive (default) class.\n",
        "\n",
        "**F1-Score:** The harmonic mean of precision and recall, providing a balanced measure.\n",
        "\n",
        "**Confusion Matrix:** To analyze the business impact of false positives (approving a bad loan) vs. false negatives (denying a good loan).\n",
        "\n",
        "**5. Justify how Ensemble Learning Improves Decision-Making**\n",
        "Using an ensemble model in this context directly translates to better business and financial decisions:\n",
        "\n",
        "**Higher Accuracy and Robustness:** A more accurate model directly reduces financial risk. By more reliably identifying potential defaulters, the institution can avoid significant losses. The model's robustness means its performance won't degrade sharply with new, unseen customer data.\n",
        "\n",
        "**Better Risk-Based Pricing:** The model's predictions (often a probability score) can be used to implement risk-based pricing. Customers with a higher predicted risk of default can be offered higher interest rates, while lower-risk customers can be offered more competitive rates, maximizing profitability while managing risk.\n",
        "\n",
        "**Improved Operational Efficiency:** Automating the initial risk assessment with a reliable model frees up loan officers to focus on borderline cases or customer service, making the entire loan approval process faster and more efficient.\n",
        "\n",
        "**Actionable Insights:** Feature importance analysis from the ensemble model can reveal the key drivers of loan default (e.g., debt-to-income ratio, number of recent credit inquiries). These insights are invaluable for refining lending policies and underwriting criteria for the future."
      ],
      "metadata": {
        "id": "J0TQTaUobMBz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Af_GEFpFbJHI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}